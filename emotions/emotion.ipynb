{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion                                             pixels     Usage\n",
       "0       0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1       0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2       2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3       4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4       6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv data into pandas dataframe\n",
    "file_path = 'fer2013.csv'\n",
    "df = pd.read_csv(file_path, dtype='a')\n",
    "\n",
    "# take a look of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset:  35887\n",
      "Emotions in dataset:  ['0' '1' '2' '3' '4' '5' '6']\n"
     ]
    }
   ],
   "source": [
    "# check number of samples and emotions in dataframe\n",
    "print('Number of samples in dataset: ', df.shape[0])\n",
    "print('Emotions in dataset: ', np.unique(df['emotion']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therer are 7 different pre-defined emotions in the data set.  \n",
    "0: Angry 1: Disgust 2: Fear 3: Happy 4: Sad 5: Surprise 6: Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe into x(facial image), y(label) data\n",
    "\n",
    "# read label data as numpy array \n",
    "label = np.array(df['emotion'])\n",
    "# read facial image as numpy array\n",
    "img = np.array(df['pixels'])\n",
    "\n",
    "# convert pixels to 2d (48, 48) image data\n",
    "img_2d = []\n",
    "for pixels in img:\n",
    "      img_2d.append(np.array([int(x) for x in pixels.split()]).reshape(48, 48))\n",
    "\n",
    "# convert to numpy array\n",
    "img_2d = np.array(img_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to expend image dimension to (48,48,1) and convert y label data to categorical data (one hot coding style) for later keras model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# expend image dimension to \n",
    "img_2d = np.expand_dims(img_2d, -1)\n",
    "\n",
    "# convert (0-6) label into (0-1) categorical data\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into trainning set and testing set (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample in training:  26915\n",
      "Number of sample in testing:  8972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xts, ytr, yts = train_test_split(img_2d, y, test_size=0.25, random_state=33)\n",
    "print('Number of sample in training: ', Xtr.shape[0]) \n",
    "print('Number of sample in testing: ', Xts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normanilze image data to make sure each pixel value is (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = Xtr / 255\n",
    "Xts = Xts / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Keras CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# input shape for the model\n",
    "input_shape = img_2d.shape[1:]\n",
    "\n",
    "# create a sequential convolutional network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model. For multicalss data, use 'categorical_crossentropy' as loss function and 'accuracy' as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimizer with learning_rate of 0.001\n",
    "learning_rate = 0.001\n",
    "adam = optimizers.Adam(lr = learning_rate)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model with training data and validate with testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 26915 samples, validate on 8972 samples\n",
      "Epoch 1/100\n",
      "26915/26915 [==============================] - 80s 3ms/step - loss: 2.0986 - acc: 0.1995 - val_loss: 1.8721 - val_acc: 0.2478\n",
      "Epoch 2/100\n",
      "26915/26915 [==============================] - 74s 3ms/step - loss: 1.8619 - acc: 0.2362 - val_loss: 1.8361 - val_acc: 0.2478\n",
      "Epoch 3/100\n",
      "26915/26915 [==============================] - 74s 3ms/step - loss: 1.8392 - acc: 0.2491 - val_loss: 1.8275 - val_acc: 0.2478\n",
      "Epoch 4/100\n",
      "26915/26915 [==============================] - 75s 3ms/step - loss: 1.8292 - acc: 0.2496 - val_loss: 1.8202 - val_acc: 0.2478\n",
      "Epoch 5/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.8213 - acc: 0.2497 - val_loss: 1.8189 - val_acc: 0.2478\n",
      "Epoch 6/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.8153 - acc: 0.2514 - val_loss: 1.8154 - val_acc: 0.2478\n",
      "Epoch 7/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.8124 - acc: 0.2514 - val_loss: 1.8026 - val_acc: 0.2478\n",
      "Epoch 8/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.7996 - acc: 0.2542 - val_loss: 1.8214 - val_acc: 0.2478\n",
      "Epoch 9/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.7819 - acc: 0.2683 - val_loss: 1.8393 - val_acc: 0.2478\n",
      "Epoch 10/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.7425 - acc: 0.2885 - val_loss: 1.9122 - val_acc: 0.1781\n",
      "Epoch 11/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.7052 - acc: 0.3041 - val_loss: 1.6372 - val_acc: 0.3247\n",
      "Epoch 12/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.6583 - acc: 0.3174 - val_loss: 1.7169 - val_acc: 0.2954\n",
      "Epoch 13/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.6126 - acc: 0.3372 - val_loss: 1.5689 - val_acc: 0.3666\n",
      "Epoch 14/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.5874 - acc: 0.3646 - val_loss: 1.6673 - val_acc: 0.3025\n",
      "Epoch 15/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.5458 - acc: 0.3831 - val_loss: 1.5485 - val_acc: 0.3695\n",
      "Epoch 16/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.5211 - acc: 0.3987 - val_loss: 1.5174 - val_acc: 0.3735\n",
      "Epoch 17/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.4894 - acc: 0.4122 - val_loss: 1.4869 - val_acc: 0.3927\n",
      "Epoch 18/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.4639 - acc: 0.4182 - val_loss: 1.4549 - val_acc: 0.4026\n",
      "Epoch 19/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.4361 - acc: 0.4304 - val_loss: 1.4533 - val_acc: 0.4055\n",
      "Epoch 20/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.4214 - acc: 0.4347 - val_loss: 1.5610 - val_acc: 0.3765\n",
      "Epoch 21/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.3963 - acc: 0.4459 - val_loss: 1.3796 - val_acc: 0.4414\n",
      "Epoch 22/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.3801 - acc: 0.4575 - val_loss: 1.3527 - val_acc: 0.4767\n",
      "Epoch 23/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.3506 - acc: 0.4777 - val_loss: 1.3951 - val_acc: 0.4692\n",
      "Epoch 24/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.3344 - acc: 0.4884 - val_loss: 1.3390 - val_acc: 0.4870\n",
      "Epoch 25/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.3060 - acc: 0.4973 - val_loss: 1.2802 - val_acc: 0.5163\n",
      "Epoch 26/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.2776 - acc: 0.5149 - val_loss: 1.2527 - val_acc: 0.5285\n",
      "Epoch 27/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.2555 - acc: 0.5234 - val_loss: 1.2444 - val_acc: 0.5351\n",
      "Epoch 28/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.2405 - acc: 0.5254 - val_loss: 1.2216 - val_acc: 0.5319\n",
      "Epoch 29/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.2095 - acc: 0.5407 - val_loss: 1.1927 - val_acc: 0.5584\n",
      "Epoch 30/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.1925 - acc: 0.5538 - val_loss: 1.1922 - val_acc: 0.5512\n",
      "Epoch 31/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.1752 - acc: 0.5617 - val_loss: 1.1847 - val_acc: 0.5673\n",
      "Epoch 32/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.1463 - acc: 0.5711 - val_loss: 1.1867 - val_acc: 0.5553\n",
      "Epoch 33/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 1.1304 - acc: 0.5786 - val_loss: 1.1675 - val_acc: 0.5640\n",
      "Epoch 34/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.1163 - acc: 0.5867 - val_loss: 1.1534 - val_acc: 0.5856\n",
      "Epoch 35/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.1007 - acc: 0.5909 - val_loss: 1.1542 - val_acc: 0.5789\n",
      "Epoch 36/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.0757 - acc: 0.6030 - val_loss: 1.1561 - val_acc: 0.5761\n",
      "Epoch 37/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.0595 - acc: 0.6122 - val_loss: 1.2745 - val_acc: 0.5388\n",
      "Epoch 38/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.0415 - acc: 0.6171 - val_loss: 1.1383 - val_acc: 0.5855\n",
      "Epoch 39/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 1.0178 - acc: 0.6266 - val_loss: 1.1526 - val_acc: 0.5933\n",
      "Epoch 40/100\n",
      "26915/26915 [==============================] - 79s 3ms/step - loss: 1.0058 - acc: 0.6355 - val_loss: 1.1820 - val_acc: 0.5751\n",
      "Epoch 41/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9912 - acc: 0.6419 - val_loss: 1.1974 - val_acc: 0.5694\n",
      "Epoch 42/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9868 - acc: 0.6434 - val_loss: 1.1573 - val_acc: 0.5826\n",
      "Epoch 43/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9587 - acc: 0.6542 - val_loss: 1.1594 - val_acc: 0.5881\n",
      "Epoch 44/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9420 - acc: 0.6604 - val_loss: 1.1927 - val_acc: 0.5876\n",
      "Epoch 45/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9218 - acc: 0.6698 - val_loss: 1.1434 - val_acc: 0.6052\n",
      "Epoch 46/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.9030 - acc: 0.6757 - val_loss: 1.4276 - val_acc: 0.5523\n",
      "Epoch 47/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.8867 - acc: 0.6842 - val_loss: 1.1996 - val_acc: 0.5964\n",
      "Epoch 48/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 0.8788 - acc: 0.6847 - val_loss: 1.2216 - val_acc: 0.6031\n",
      "Epoch 49/100\n",
      "26915/26915 [==============================] - 75s 3ms/step - loss: 0.8629 - acc: 0.6924 - val_loss: 1.2606 - val_acc: 0.5665\n",
      "Epoch 50/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.8556 - acc: 0.6941 - val_loss: 1.2486 - val_acc: 0.5831\n",
      "Epoch 51/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.8326 - acc: 0.6989 - val_loss: 1.1774 - val_acc: 0.5955\n",
      "Epoch 52/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.8176 - acc: 0.7108 - val_loss: 1.2162 - val_acc: 0.6043\n",
      "Epoch 53/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.8078 - acc: 0.7150 - val_loss: 1.2038 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7910 - acc: 0.7235 - val_loss: 1.2160 - val_acc: 0.6078\n",
      "Epoch 55/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7852 - acc: 0.7236 - val_loss: 1.2214 - val_acc: 0.6121\n",
      "Epoch 56/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7465 - acc: 0.7379 - val_loss: 1.3023 - val_acc: 0.6120\n",
      "Epoch 57/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7551 - acc: 0.7351 - val_loss: 1.2273 - val_acc: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7324 - acc: 0.7483 - val_loss: 1.2286 - val_acc: 0.6110\n",
      "Epoch 59/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7257 - acc: 0.7489 - val_loss: 1.3099 - val_acc: 0.6204\n",
      "Epoch 60/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7254 - acc: 0.7491 - val_loss: 1.2449 - val_acc: 0.5955\n",
      "Epoch 61/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.7031 - acc: 0.7572 - val_loss: 1.3115 - val_acc: 0.6169\n",
      "Epoch 62/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6935 - acc: 0.7621 - val_loss: 1.2694 - val_acc: 0.6197\n",
      "Epoch 63/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6761 - acc: 0.7695 - val_loss: 1.3299 - val_acc: 0.6083\n",
      "Epoch 64/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6784 - acc: 0.7678 - val_loss: 1.3513 - val_acc: 0.5960\n",
      "Epoch 65/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6637 - acc: 0.7717 - val_loss: 1.3253 - val_acc: 0.5985\n",
      "Epoch 66/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6480 - acc: 0.7789 - val_loss: 1.2787 - val_acc: 0.6258\n",
      "Epoch 67/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6458 - acc: 0.7822 - val_loss: 1.2939 - val_acc: 0.6242\n",
      "Epoch 68/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6306 - acc: 0.7857 - val_loss: 1.2733 - val_acc: 0.6086\n",
      "Epoch 69/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6221 - acc: 0.7910 - val_loss: 1.3040 - val_acc: 0.6121\n",
      "Epoch 70/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6030 - acc: 0.7967 - val_loss: 1.4409 - val_acc: 0.6158\n",
      "Epoch 71/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.6035 - acc: 0.7968 - val_loss: 1.4434 - val_acc: 0.6108\n",
      "Epoch 72/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5856 - acc: 0.8028 - val_loss: 1.3615 - val_acc: 0.6038\n",
      "Epoch 73/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5826 - acc: 0.8063 - val_loss: 1.4159 - val_acc: 0.5897\n",
      "Epoch 74/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 0.5638 - acc: 0.8145 - val_loss: 1.5219 - val_acc: 0.5779\n",
      "Epoch 75/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5772 - acc: 0.8111 - val_loss: 1.2935 - val_acc: 0.6215\n",
      "Epoch 76/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5552 - acc: 0.8181 - val_loss: 1.3463 - val_acc: 0.6225\n",
      "Epoch 77/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5500 - acc: 0.8169 - val_loss: 1.2937 - val_acc: 0.6187\n",
      "Epoch 78/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 0.5283 - acc: 0.8302 - val_loss: 1.4755 - val_acc: 0.6093\n",
      "Epoch 79/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 0.5291 - acc: 0.8288 - val_loss: 1.4748 - val_acc: 0.6207\n",
      "Epoch 80/100\n",
      "26915/26915 [==============================] - 77s 3ms/step - loss: 0.5256 - acc: 0.8288 - val_loss: 1.3673 - val_acc: 0.6187\n",
      "Epoch 81/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5185 - acc: 0.8336 - val_loss: 1.3987 - val_acc: 0.6293\n",
      "Epoch 82/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.5128 - acc: 0.8367 - val_loss: 1.5097 - val_acc: 0.6100\n",
      "Epoch 83/100\n",
      "26915/26915 [==============================] - 79s 3ms/step - loss: 0.5162 - acc: 0.8315 - val_loss: 1.4085 - val_acc: 0.6307\n",
      "Epoch 84/100\n",
      "26915/26915 [==============================] - 80s 3ms/step - loss: 0.4940 - acc: 0.8415 - val_loss: 1.3767 - val_acc: 0.6228\n",
      "Epoch 85/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4835 - acc: 0.8456 - val_loss: 1.4418 - val_acc: 0.6179s - loss:\n",
      "Epoch 86/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4826 - acc: 0.8476 - val_loss: 1.4821 - val_acc: 0.6203\n",
      "Epoch 87/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4848 - acc: 0.8491 - val_loss: 1.4696 - val_acc: 0.6317\n",
      "Epoch 88/100\n",
      "26915/26915 [==============================] - 79s 3ms/step - loss: 0.4620 - acc: 0.8543 - val_loss: 1.4224 - val_acc: 0.6164\n",
      "Epoch 89/100\n",
      "26915/26915 [==============================] - 75s 3ms/step - loss: 0.4566 - acc: 0.8557 - val_loss: 1.4698 - val_acc: 0.6210\n",
      "Epoch 90/100\n",
      "26915/26915 [==============================] - 80s 3ms/step - loss: 0.4394 - acc: 0.8644 - val_loss: 1.5431 - val_acc: 0.6336\n",
      "Epoch 91/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4568 - acc: 0.8592 - val_loss: 2.4391 - val_acc: 0.3722\n",
      "Epoch 92/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.5181 - acc: 0.8385 - val_loss: 1.4489 - val_acc: 0.6244\n",
      "Epoch 93/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4651 - acc: 0.8564 - val_loss: 1.4474 - val_acc: 0.6335\n",
      "Epoch 94/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4371 - acc: 0.8665 - val_loss: 1.4955 - val_acc: 0.6115\n",
      "Epoch 95/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4329 - acc: 0.8663 - val_loss: 1.5754 - val_acc: 0.6297\n",
      "Epoch 96/100\n",
      "26915/26915 [==============================] - 82s 3ms/step - loss: 0.4193 - acc: 0.8717 - val_loss: 1.5633 - val_acc: 0.6309\n",
      "Epoch 97/100\n",
      "26915/26915 [==============================] - 80s 3ms/step - loss: 0.4098 - acc: 0.8742 - val_loss: 1.5446 - val_acc: 0.6220\n",
      "Epoch 98/100\n",
      "26915/26915 [==============================] - 76s 3ms/step - loss: 0.4119 - acc: 0.8726 - val_loss: 1.6486 - val_acc: 0.6282\n",
      "Epoch 99/100\n",
      "26915/26915 [==============================] - 78s 3ms/step - loss: 0.4015 - acc: 0.8819 - val_loss: 1.6540 - val_acc: 0.6273\n",
      "Epoch 100/100\n",
      "26915/26915 [==============================] - 80s 3ms/step - loss: 0.4040 - acc: 0.8739 - val_loss: 1.5805 - val_acc: 0.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb479395f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bacth size and number of epochs\n",
    "batch_size = 64\n",
    "nepochs = 100\n",
    "\n",
    "# fit the model\n",
    "model.fit(Xtr, ytr, epochs=100, batch_size = batch_size,\n",
    "          validation_data=(Xts, yts), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model to a file\n",
    "model_json = model.to_json()\n",
    "with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
