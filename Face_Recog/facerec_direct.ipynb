{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Before you run this file , please download the compressed trained model(facemodel.h5) and depress it in the model folder. Then you can just run all blocks and check the real performance of this system. Please adjust your camera so that the stickers are in the right position(need to be improved). And moving too fast might cause exception.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IMAGE_SIZE = 128 # we assign the image as (128,128,3)\n",
    "\n",
    "def resize_image(image, height = IMAGE_SIZE, width = IMAGE_SIZE):\n",
    "    top, bottom, left, right = (0,0,0,0)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # find the longer edge if the image is not square\n",
    "    longest_edge = max(h,w)\n",
    "    \n",
    "    if h < longest_edge:\n",
    "        dh = longest_edge - h\n",
    "        top = dh // 2\n",
    "        bottom = dh - top\n",
    "    elif w < longest_edge:\n",
    "        dw = longest_edge - w\n",
    "        left = dw // 2\n",
    "        right = dw - left\n",
    "    else:\n",
    "        pass \n",
    "    \n",
    "    BLACK = [0,0,0]\n",
    "    constant = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    return cv2.resize(constant, (height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def build_model(self, dataset, nb_classes = 5):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = dataset.input_shape))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Conv2D(32, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        self.model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Conv2D(64, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(nb_classes))\n",
    "        self.model.add(Activation('softmax'))\n",
    "    def train(self, dataset, batch_size = 128, nb_epoch = 6):\n",
    "        \n",
    "        self.model.compile(loss = 'categorical_crossentropy', \n",
    "                           optimizer = 'ADAM',\n",
    "                           metrics = ['accuracy'])\n",
    "        self.model.fit(dataset.train_images, \n",
    "                           dataset.train_labels, \n",
    "                           batch_size = batch_size,\n",
    "                           epochs = nb_epoch, \n",
    "                           shuffle = True)\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        score = self.model.evaluate(dataset.test_images, dataset.test_labels)\n",
    "        print(\"%s: %.3f%%\" % (self.model.metrics_names[1], score[1] * 100))\n",
    "        \n",
    "    def save_model(self, file_path):\n",
    "        self.model.save(file_path)\n",
    "    def load_model(self, file_path):\n",
    "        self.model = load_model(file_path)\n",
    "    def face_predict(self, image):\n",
    "        #use resize function defined before\n",
    "        image = resize_image(image)\n",
    "        image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        result = self.model.predict(image)\n",
    "        return result.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Method\n",
    "def get_facecover(x, y, w, h, img, rgb_image, a):\n",
    "    eyes_center = ((2 * x + w)//2 , (2 * y)//2) # find the the center of the target's eyes\n",
    "#     factor = 1.2  # manual control size factor  \n",
    "    resized_image_h = h  # resized_image_h = h * factor\n",
    "    resized_image_w = w \n",
    "\n",
    "    if resized_image_h > y:\n",
    "        resized_image_h = y-1\n",
    "\n",
    "    # Resized image based on resized h and w\n",
    "    resized_image = cv2.resize(rgb_image,(resized_image_w,resized_image_h))\n",
    "    mask = cv2.resize(a,(resized_image_w,resized_image_h))\n",
    "    mask_inv =  cv2.bitwise_not(mask)\n",
    "    # Seted shifing offset\n",
    "    dh = int(1.015 * h)\n",
    "    dw = int(-0.2 * w) \n",
    "    \n",
    "    # Find face\n",
    "    bg_roi = img[y+dh-resized_image_h:y+dh,(eyes_center[0]-resized_image_w//3)+dw:(eyes_center[0]+resized_image_w//3*2)+dw]\n",
    "    bg_roi = bg_roi.astype(float)\n",
    "    \n",
    "    # Generate Mask\n",
    "    mask_inv = cv2.merge((mask_inv,mask_inv,mask_inv))\n",
    "    alpha = mask_inv.astype(float)/255\n",
    "\n",
    "    # resize alpha for future calculation\n",
    "    alpha = cv2.resize(alpha,(bg_roi.shape[1],bg_roi.shape[0]))\n",
    "    bg = cv2.multiply(alpha, bg_roi)\n",
    "    bg = bg.astype('uint8')\n",
    "\n",
    "\n",
    "    # Get the area of face mask\n",
    "    image = cv2.bitwise_and(resized_image,resized_image,mask = mask)\n",
    "    image = cv2.resize(image,(bg_roi.shape[1],bg_roi.shape[0]))\n",
    "    # Add face mask to the target area\n",
    "    add_image = cv2.add(bg,image)\n",
    "\n",
    "    # Replace the original with the face mask\n",
    "    img[y+dh-resized_image_h:y+dh,(eyes_center[0]-resized_image_w//3)+dw:(eyes_center[0]+resized_image_w//3*2)+dw] = add_image.copy()\n",
    "    \n",
    "    # Return the edited frame\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "facial_file = ['angry','hate','fear','happy','sad','surprise','neutral']\n",
    "\n",
    "facial_dict = {}\n",
    "for i in range(7):\n",
    "    print(i)\n",
    "    face_img = cv2.imread(facial_file[i] + '.png',cv2.IMREAD_UNCHANGED)\n",
    "    r,g,b,a = cv2.split(face_img) \n",
    "    rgb_face = cv2.merge((r,g,b))\n",
    "    cv2.imwrite(facial_file[i]+'_alpha.png',a)\n",
    "    facial_dict[facial_file[i]] = [rgb_face,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "# Def emotions labels\n",
    "emotion_labels = {\n",
    "    0: 'angry',\n",
    "    1: 'hate',\n",
    "    2: 'fear',\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'surprise',\n",
    "    6: 'neutral'\n",
    "}\n",
    "\n",
    "# Load emotion classifier\n",
    "emotion_classifier = load_model('model/simple_CNN.530-0.65.hdf5')\n",
    "# Load face detection model\n",
    "model = Model()\n",
    "model.load_model(file_path = './model/facemodel.h5')    \n",
    "\n",
    "# Create OpenCv window\n",
    "cv2.namedWindow('Detecting your face.') \n",
    "color = (0, 255, 0)\n",
    "\n",
    "# Load haarcascade classifier\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "# Capture the real time image frame\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "        ok, frame = cap.read() # type(frame) <class 'numpy.ndarray'>\n",
    "        if not ok:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # gray scale the frame\n",
    "        frame2 = frame.copy()\n",
    "        faceRects=classifier.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=3,minSize=(32,32))\n",
    "        \n",
    "        # If detected target face\n",
    "        if len(faceRects) > 0:\n",
    "            \n",
    "            for faceRect in faceRects: \n",
    "                \n",
    "                x, y, w, h = faceRect                \n",
    "                image = frame[y - 10: y + h + 10, x - 10: x + w + 10].copy()\n",
    "                \n",
    "                \n",
    "                # Dectect if the image is none\n",
    "                # if we won't do this step, there will be an error:\n",
    "                    # error error (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n",
    "                if image is None:  \n",
    "                    break\n",
    "                else:\n",
    "                    if image is not None:\n",
    "                        gray_face = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                        gray_face = cv2.resize(gray_face,(48,48))\n",
    "                        gray_face = gray_face/255.0\n",
    "                        gray_face =np.expand_dims(gray_face,0)\n",
    "                        gray_face =np.expand_dims(gray_face,-1)\n",
    "                        \n",
    "                        # Predict emotion from the gray scale image\n",
    "                        emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))\n",
    "                        emotion = emotion_labels[emotion_label_arg]\n",
    "                        faceID = model.face_predict(image)\n",
    "                        \n",
    "                        # Make a face mask based on the emotions\n",
    "                        img = frame2.copy()\n",
    "                        img = get_facecover(x, y, w, h, img, facial_dict[emotion][0], facial_dict[emotion][1])\n",
    "                        frame2 = img.copy()\n",
    "                        \n",
    "                        # Show the target's name and emotion\n",
    "                        if faceID[0] == 0:                                                        \n",
    "                            cv2.rectangle(frame2, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                            cv2.putText(frame2,'Yan is '+ emotion, \n",
    "                                    (x + 30, y + 30),                      # Coordinate\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,              # Font\n",
    "                                    1,                                     # Word size\n",
    "                                    (255,0,255),                           # Word color\n",
    "                                    2)                                     # Word's line width\n",
    "                            \n",
    "                        elif faceID[0] == 1:\n",
    "                            cv2.rectangle(frame2, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                            cv2.putText(frame2,'Yujie is ' + emotion, \n",
    "                                    (x + 30, y + 30),                     \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,             \n",
    "                                    1,                                     \n",
    "                                    (255,0,255),                        \n",
    "                                    2)                                   \n",
    "                        elif faceID[0] == 2:\n",
    "                            cv2.rectangle(frame2, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                            cv2.putText(frame2,'Liang is ' + emotion, \n",
    "                                    (x + 30, y + 30),                      \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,             \n",
    "                                    1,                                  \n",
    "                                    (255,0,255),                          \n",
    "                                    2)                                     \n",
    "                        elif faceID[0] == 4:\n",
    "                            cv2.rectangle(frame2, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                            cv2.putText(frame2,'Zuxian is ' + emotion, \n",
    "                                    (x + 30, y + 30),                     \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,             \n",
    "                                    1,                                  \n",
    "                                    (255,0,255),                           \n",
    "                                    2)                                     \n",
    "                        else:\n",
    "                            cv2.rectangle(frame2, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                            cv2.putText(frame2,'Unknown is '+ emotion, \n",
    "                                    (x + 30, y + 30),                    \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,            \n",
    "                                    1,                                   \n",
    "                                    (255,0,255),                         \n",
    "                                    2)    \n",
    "        # Show the edited frame on the screen\n",
    "                \n",
    "        cv2.imshow(\"Detecting your face.\", frame2)\n",
    "        \n",
    "        # Press to q to exit\n",
    "       \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
